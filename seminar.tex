\documentclass[	runningheads,
				a4paper]{llncs}
\usepackage{url}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{hyperref}

% Support for special characters like "Umlaute"
\usepackage[utf8]{inputenc}


\usepackage[english]{babel}


%*********************************************************************%
% META                                                                %
%*********************************************************************%

\newcommand{\university}{Saarland University}
\newcommand{\school}{Saarland Informatics Campus}


\newcommand{\thetitle}{Seminar: Understanding of configurable software systems}
\newcommand{\shorttitle}{Seminar: Understanding of configurable software systems}
\newcommand{\thedate}{January 11}


\newcommand{\theforename}{Bipin}
\newcommand{\thesurname}{Oli}

% Advisors

\newcommand{\advisor}{Advisors}

\newcommand{\advisors}{Prof. Sven Apel, \\ Christian Hechtl}

% Title for the seminar

\newcommand{\theseminartitle}{Dynamic symbolic execution (concolic execution)}


%*********************************************************************%
% THE DOCUMENT                                                        %
%*********************************************************************%

\begin{document}
%*********************************************************************%
% TITLE                                                               %
%*********************************************************************%

% Arabic page numbering
\mainmatter 
	
% Title including a subtitle for the name of the seminar
\title{\theseminartitle \\ \small \thetitle}

\author{\theforename\ \thesurname \small \\ \ \\ \advisor : \ \advisors}

% (Optional) This will appear near the page number
\authorrunning{\shorttitle}

\institute{\school ,\\ \university}


\maketitle
%*********************************************************************%
% CONTENT                                                             %
%*********************************************************************%
% Introduction
\section{Abstract}
Concolic execution \cite{godefroid2005dart} is a software verification technique that performs symbolic execution together with concrete input values. Concrete values are selected with the help of a constraint solver to guide a program flow in a particular direction. The selection of concrete values helps to scale the verification to a larger program as it makes the symbolic constraints smaller by selecting specific branches in the program. Compared to random execution, this allows us to guide the analysis in a direction likely to have bugs which makes this technique powerful. However, in doing so we sacrifice the completeness of the analysis in favor of the depth of analysis. The sheer number of branches in a large program makes it difficult to perform a complete analysis, so we have to prioritize the branches likely to contribute to finding a bug. There have been a lot of studies to deal with this path explosion problem. In this paper, I have presented state-of-the-art methods to deal with this problem.

\section{Introduction}
\begin{itemize}
	\item What is it?
	\item Where did it start?
	\item How does it work?
	\item Give an example
	\item Why is it important?
	\item It's contributions
	\item It's limitations
	\item Example of the use of this technique in finding bugs in configurable system eg result of SAGE, EXE, etc.
\end{itemize}


\section{Body}

% ------------------------------
\subsection{2007: Performing dynamic test generation compositionally}
\cite[paper]{godefroid2007compositional}

\subsubsection{Gist:}
The general idea behind this new search algorithm is to perform dynamic  test generation compositionally, by adapting (dualizing) known techniques for interproce-dural static analysis to the context of automated dynamic test gener-ation.

\subsubsection{Methodlogy:}
new search algorithm called SMART which stands for duce a new algorithm, dubbed SMARTfor Systematic Modular Automated Random Testing, a more efficent search method then DART without compromising
completeness. It tests functions in isolation, collects testing results as function summaries ex-pressed using preconditions on function inputs and postconditionson function outputs, and then re-use those summaries when testinghigher-level functions.

A SMART search performs dynamic test generation composi-tionally,  using  function  summaries  as  defined  previously.  Thosesummaries  are  dynamically  computed  in  a  top-down  mannerthrough the call-flow graphGPofP. Starting from the top-levelfunction, one executes the program (initially on some random in-puts) until one  reaches  a first functionfwhose execution termi-nates on a return orhaltstatement. One then backtracks insidefas much as  possible  using DART, computing summaries  for thatfunction and each of those DART-triggered executions. When thissearch (backtracking)  infis over, one then resumes the originalexecution wherefwas called,  this time treatingfessentially asa black-box,  i.e., without analyzing it and re-using its previouslycomputed  summary  instead. 

\subsubsection{Result:}
SMART can perform dynamic test generation com-positionally without any reduction in program path coverage. Wealso show that, given a bound on the maximum number of feasiblepaths in individual program functions, the number of program exe-cutions explored by SMART is linear in that bound, while the num-ber of program executions explored by DART can be exponentialin that bound.
SMART = scalable DART

% ------------------------------

\subsection{2006: Software Partitioning for Effective Automated Unit Testing}
\cite{chakrabarti2006software}

\subsubsection{Gist:}
present an approach thatidentifies control and data inter-dependencies between soft-ware components using static program analysis, and dividesthe source code into units where highly-intertwined compo-nents are grouped together. Those units can then be testedin isolation using automated test generation techniques andtools,  such as dynamic software model checkers

\subsubsection{Methodlogy:}
group together functions or components that share interfaces of complexity higher than 
a particular threshold. Complexity is determined by the popularity and sharing of code. The idea is that 
if the function is very popular and is being called from a lot of places then it is likely that it is not closely liked to any component. 
And, the sharing of code meaning if two functions share many of the same functions then it is likely that the higher level operation they perform is close to each other.

\subsubsection{Configurability part:}
evaluated the effectiveness by applying the algorithm to the open source implementation of oSIP protocol (http://www.gnu.org/software/osip/osip.html) which is a telephony protocol for call establishment. 


\subsubsection{Result:}
showing  that  auto-matic  software  partitioning  can  significantly  increase  testcoverage without generating too many false alarms causedby unrealistic inputs being injected at interfaces betweenunits

% ------------------------------
\subsection{2007: Hybrid concolic testing (**)}

\subsubsection{Gist:}
an algorithm that in-terleaves random testing with concolic execution to obtainboth a deep and a wide exploration of program state space.Our algorithm generates test inputs automatically by inter-leaving  random  testing  until  saturation  with  bounded  ex-haustive  symbolic  exploration  of  program  points.   It  thuscombines the ability of random search to reachdeeppro-gram states quickly together with the ability of concolic test-ing to explore states in a neighborhood exhaustively. 

\subsubsection{Methodlogy:}
presenthybrid concolic testing, a simple algorithmthat  interleaves  the  application  of  random  tests  with  con-colic  testing  to  achieve  deep  and  wide  exploration  of  theprogram  state  space.   From  the  initial  program  state,  hy-brid  concolic  testing  starts  by  performing  random  testingto improve coverage.  When random testingsaturates, thatis,  does  not  produce  any  new  coverage  points  after  run-ning  some  predetermined  number  of  steps,  the  algorithmautomatically switches to concolic executionfrom the cur-rent program stateto perform an exhaustive bounded depthsearch for an uncovered coverage point.  As soon as one isfound,  the algorithm reverts back to concrete mode.   Theinterleaving of random testing and concolic execution thususes both the capacity of random testing to inexpensivelygenerate deep program states through long program execu-tions and the capability of concolic testing to exhaustivelyand symbolically search for new paths with a limited looka-head.

The interleaving of random and symbolic techniques isthe crucial insight that distinguishes hybrid concolic testingfrom a naive approach that simply runs random and con-colic tests in parallel on a program.  This is because manyprograms show behaviors where the program must reach aparticular statesand then follow a precise sequence of in-put events 'alpha' order to get to a required coverage point.It  is  often  easy  to  reachsusing  random  testing,  but  notthen to generate the precise sequence of events 'alpha'.  On theother hand, while it is usually easy for concolic testing togenerate 'sigma', concolic testing gets stuck in exploring a hugenumber of program paths before even reaching the states.

In the end, hybrid concolic testing has the same limita-tions of symbolic execution based test generation:  the dis-covery of uncovered points depends on the scalability andexpressiveness of the constraint solver, and the exhaustivesearch  for  uncovered  points  is  limited  by  the  number  ofpaths to be explored. Therefore, in general, hybrid concolictesting may not achieve 100 percent coverage, although it can im-prove random testing considerably. Further, the algorithmisnot a panacea for all software quality issues. While we pro-vide an automatic mechanism for test input generation, allthe other effort required in testing, for example, test oraclegeneration, assertion based verification, and mock environ-ment creation still have to be performed as with any othertest input generation algorithm.  Further, we look for codecoverage,  which may or may not be an indicator of codereliability.

\subsubsection{Configurability part:}
compare random,  concolic,  andhybrid concolic testing on the VIM text editor (150K linesof C code) and on an implementation of the red-black treedata structure. Our experiments indicate that for a fixed test-ing budget, hybrid concolic testing technique outperformsboth random and concolic in terms of branch coverage. of the state space exhaustively. In contrast, hybrid concolictesting switches to inexpensive random test-ing as soon as it identifiessomeuncovered point, relying onfast random testing to explore as much of the state space aspossible.  In this way, it avoids expensive constraint solv-ing to perform exhaustive search in some part of the statespace. Moreover, if random testing does not hit a new cov-erage point, it can take advantage of the locally exhaustivesearch provided by concolic testing to continue from a newcoverage point

% ------------------------------
\subsection{2008: Heuristics for Scalable Dynamic Test Generation}

\subsubsection{Gist:}

\subsubsection{Methodlogy:}

\subsubsection{Configurability part:}

\subsubsection{Result:}

% ------------------------------
\subsection{<<paper>>}

\subsubsection{Gist:}

\subsubsection{Methodlogy:}

\subsubsection{Configurability part:}

\subsubsection{Result:}



% ------------------------------
\section{Different catagorical bodies}
\begin{itemize}
	\item summerize, give an overview of the main points of each source and combine them into a coherent whole
	\item Analyze and interpret: don’t just paraphrase other researchers—add your own interpretations where possible, discussing the significance of findings in relation to the literature as a whole
	\item Critically evaluate: mention the strengths and weaknesses of your sources
	\item Write in well-structured paragraphs: use transition words and topic sentences to draw connections, comparisons and contrasts
\end{itemize}

\section{Conclusion}

\section{Papers}


\begin{itemize}
  \item 2006: they worked on backtracking algorithms for search heuristics \cite{yan2006backtracking}
  \item 2007: they combined the fuzzing techniques to improve the coverage \cite{majumdar2007hybrid} \cite{godefroid2007compositional} \cite{godefroid2012sage}
  \item 2008: Heuristic based approach to select the branches \cite{kousik2008heuristic}
  \item 2009: they worked on the fitness guided approach to improve the coverage \cite{xie2009fitness}
  \item 2013: they boosted concolic testing by subsuming paths that are guaranteed to not hit a bug with their interpolation technique \cite{jaffar2013boosting}
  \item 2014: they introduced a concept of context guided search strategy \cite{seo2014we}
  \item 2018: automatic selection of suitable heuristic \cite{cha2018automatically}
  \item 2018: template guided approach \cite{cha2018template}
  \item 2018: based on probability of program paths and the cost of constraint solving \cite{wang2018towards}
  \item 2018: they improved the speed of SMT solver by removing the IR layer making it more practical to keep bigger constraints \cite{yun2018qsym}
  \item 2019: fuzzy search strategy \cite{fsct2019}
  \item 2019: adaptably changing search heuristics \cite{adapt2019heuristic}
  \item 2021: Pathcrawler: proposed different strategies to improve the performance of concolic execution on exhaustive branch coverage \cite{pathcrawler2021}
  \item 2022: Dr. Pathfinder \cite{drPathfinder2022} combined concolic execution with deep reinforement learning to prioritize deep paths over shallow ones for hybrid fuzzing
\end{itemize}


%*********************************************************************%
% APPENDIX                                                            %
%*********************************************************************%

% \appendix
% \section{Appendix}
% Insert the appendix here. You can alternatively include files via: \include{pathToFile}

%*********************************************************************%
% LITERATURE                                                          %
%*********************************************************************%
% As a recommendation JabRef might be a useful tool for this section. Use myRefs.bib therefore
\phantomsection
\bibliographystyle{splncs03}
\bibliography{literature}
	
\end{document}
